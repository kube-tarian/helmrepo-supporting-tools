nameOverride: ""
fullnameOverride: ""

# Chart debug mode
# (eg. disable helm hook delete policy)
debug: false

# Custom Service account management
serviceAccount:
  # Whether to create service account or not
  create: false

  # Name of the service account, default: temporal.fullname
  name:

  # extraAnnotations would let users add additional annotations
  extraAnnotations:

server:
  enabled: true
  sidecarContainers: {}
  image:
    repository: ghcr.io/kube-tarian/helmrepo-supporting-tools/server
    tag: 1.22.1
    pullPolicy: IfNotPresent

  # Global default settings (can be overridden per service)
  replicaCount: 1
  metrics:
    # Annotate pods directly with Prometheus annotations.
    # Use this if you installed Prometheus from a Helm chart.
    annotations:
      enabled: true
    # Additional tags to be added to Prometheus metrics
    tags: {}
    # Enable Prometheus ServiceMonitor
    # Use this if you installed the Prometheus Operator (https://github.com/coreos/prometheus-operator).
    serviceMonitor:
      enabled: true
      interval: 30s
      # Set additional lables to all the ServiceMonitor resources
      additionalLabels: {}
      #  label1: value1
      #  label2: value2
      # Set Prometheus metric_relabel_configs via ServiceMonitor
      # Use metricRelabelings to adjust metric and label names as needed
      metricRelabelings: 
        - action: replace
          regex: .*
          replacement: capten-controlplane
          separator: ;
          targetLabel: cluster_name
      # - action: replace
      #   sourceLabels:
      #   - exported_namespace
      #   targetLabel: temporal_namespace
      # - action: replace
      #   regex: service_errors_(.+)
      #   replacement: ${1}
      #   sourceLabels:
      #   - __name__
      #   targetLabel: temporal_error_kind
      # - action: replace
      #   regex: service_errors_.+
      #   replacement: temporal_service_errors
      #   sourceLabels:
      #   - __name__
      #   targetLabel: __name__
    prometheus:
      timerType: histogram
  podAnnotations: {}
  podLabels: {}
  secretLabels: {}
  secretAnnotations: {}
  resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #  cpu: 100m
  #  memory: 128Mi
  # requests:
  #  cpu: 100m
  #  memory: 128Mi
  nodeSelector: {}
  tolerations: []
  affinity: {}
  additionalVolumes: []
  additionalVolumeMounts: []
  additionalEnv: []
  securityContext:
    fsGroup: 1000
    runAsUser: 1000

  config:
    logLevel: "debug,info"
    numHistoryShards: 512
    persistence:
      defaultStore: default
      default:
        driver: "sql"

        sql:
          driver: "postgres"
          host: postgres-postgresql
          port: 5432
          database: temporal
          user: temporal
          existingSecret: postgres-postgresql
          # password: 
          # for a production deployment use this instead of `password` and provision the secret beforehand e.g. with a sealed secret
          # it has a single key called `password`
          maxConns: 20
          maxConnLifetime: "1h"
          # tls:
          #  enabled: true
          #  enableHostVerification: true
          #  serverName: _HOST_ # this is strictly required when using serverless CRDB offerings

      visibility:
        driver: "sql"

        sql:
          driver: "postgres"
          host: postgres-postgresql
          port: 5432
          database: temporal_visibility
          user: temporal
          existingSecret: postgres-postgresql
          # password: 
          # for a production deployment use this instead of `password` and provision the secret beforehand e.g. with a sealed secret
          # it has a single key called `password`
          maxConns: 20
          maxConnLifetime: "1h"
          # tls:
          #  enabled: true
          #  enableHostVerification: true
          #  serverName: _HOST_ # this is strictly required when using serverless CRDB offerings

  frontend:
    replicaCount: 2
    service:
      annotations: {} # Evaluated as template
      type: ClusterIP
      port: 7233
    metrics:
      annotations:
        enabled: true
      serviceMonitor: 
        enabled: true
      prometheus: {}
      # timerType: histogram
    podAnnotations: {}
    podLabels: {}
    resources: {}
    nodeSelector: {}
    tolerations: []
    affinity: {}
    additionalEnv: []
    containerSecurityContext: {}
    topologySpreadConstraints: {}
    podDisruptionBudget: {}

  history:
    replicaCount: 2
    service:
      # type: ClusterIP
      port: 7234
    metrics:
      annotations:
        enabled: true
      serviceMonitor:
        enabled: true
      prometheus: {}
      # timerType: histogram
    podAnnotations: {}
    podLabels: {}
    resources: {}
    nodeSelector: {}
    tolerations: []
    affinity: {}
    additionalEnv: []
    containerSecurityContext: {}
    topologySpreadConstraints: {}
    podDisruptionBudget: {}

  matching:
    replicaCount: 2
    service:
      # type: ClusterIP
      port: 7235
    metrics:
      annotations:
        enabled: false
      serviceMonitor:
        enabled: true
      prometheus: {}
      # timerType: histogram
    podAnnotations: {}
    podLabels: {}
    resources: {}
    nodeSelector: {}
    tolerations: []
    affinity: {}
    additionalEnv: []
    containerSecurityContext: {}
    topologySpreadConstraints: {}
    podDisruptionBudget: {}

  worker:
    replicaCount: 3
    service:
      # type: ClusterIP
      port: 7239
    metrics:
      annotations:
        enabled: true
      serviceMonitor:
        enabled: true
      prometheus: {}
      # timerType: histogram
    podAnnotations: {}
    podLabels: {}
    resources: {}
    nodeSelector: {}
    tolerations: []
    affinity: {}
    additionalEnv: []
    containerSecurityContext: {}
    topologySpreadConstraints: {}
    podDisruptionBudget: {}

admintools:
  enabled: true
  image:
    repository: ghcr.io/kube-tarian/helmrepo-supporting-tools/admin-tools
    tag: 1.22.1
    pullPolicy: IfNotPresent

  service:
    type: ClusterIP
    port: 22
    annotations: {}
  podLabels: {}
  podAnnotations: {}
  nodeSelector: {}
  tolerations: []
  affinity: {}
  additionalEnv: []
  resources: {}
  containerSecurityContext: {}
  securityContext: {}
  podDisruptionBudget: {}

web:
  enabled: false
  config:
    # server/config.yml file content
    auth:
      enabled: false
    routing:
      default_to_namespace: # internal use only
      issue_report_link: https://github.com/temporalio/web/issues/new/choose # set this field if you need to direct people to internal support forums

  replicaCount: 1

  image:
    repository: temporalio/ui
    tag: 2.16.2
    pullPolicy: IfNotPresent

  service:
    # set type to NodePort if access to web needs access from outside the cluster
    # for more info see https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types
    type: ClusterIP
    port: 8080
    annotations: {}
    # loadBalancerIP:

  ingress:
    enabled: false
    # className:
    annotations: {}
    # kubernetes.io/ingress.class: traefik
    # ingress.kubernetes.io/ssl-redirect: "false"
    # traefik.frontend.rule.type: PathPrefix
    hosts:
      - "/"
      # - "domain.com/xyz"
      # - "domain.com"
    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  podAnnotations: {}
  podLabels: {}

  resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #  cpu: 100m
  #  memory: 128Mi
  # requests:
  #  cpu: 100m
  #  memory: 128Mi

  nodeSelector: {}

  tolerations: []

  affinity: {}

  additionalVolumes: []
  additionalVolumeMounts: []

  additionalEnv: []

  containerSecurityContext: {}
  
  securityContext: {}

schema:
  setup:
    enabled: true
    backoffLimit: 100
  update:
    enabled: true
    backoffLimit: 100
  resources: {}
  containerSecurityContext: {}
  securityContext: {}

elasticsearch:
  enabled: false
  replicas: 3
  persistence:
    enabled: false
  imageTag: 7.17.3
  host: elasticsearch-master-headless
  scheme: http
  port: 9200
  version: "v7"
  logLevel: "error"
  username: ""
  password: ""
  visibilityIndex: "temporal_visibility_v1_dev"

prometheus:
  enabled: false
  nodeExporter:
    enabled: false

grafana:
  enabled: false
  replicas: 1
  testFramework:
    enabled: false
  rbac:
    create: false
    pspEnabled: false
    namespaced: true
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: "default"
          orgId: 1
          folder: ""
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/default
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: TemporalMetrics
          type: prometheus
          url: http://{{ .Release.Name }}-prometheus-server
          access: proxy
          isDefault: true
  dashboards:
    default:
      server-general-github:
        url: https://raw.githubusercontent.com/temporalio/dashboards/helm/server/server-general.json
        datasource: TemporalMetrics
      sdk-general-github:
        url: https://raw.githubusercontent.com/temporalio/dashboards/helm/sdk/sdk-general.json
        datasource: TemporalMetrics
      misc-advanced-visibility-specific-github:
        url: https://raw.githubusercontent.com/temporalio/dashboards/helm/misc/advanced-visibility-specific.json
        datasource: TemporalMetrics
      misc-clustermonitoring-kubernetes-github:
        url: https://raw.githubusercontent.com/temporalio/dashboards/helm/misc/clustermonitoring-kubernetes.json
        datasource: TemporalMetrics
      misc-frontend-service-specific-github:
        url: https://raw.githubusercontent.com/temporalio/dashboards/helm/misc/frontend-service-specific.json
        datasource: TemporalMetrics
      misc-history-service-specific-github:
        url: https://raw.githubusercontent.com/temporalio/dashboards/helm/misc/history-service-specific.json
        datasource: TemporalMetrics
      misc-matching-service-specific-github:
        url: https://raw.githubusercontent.com/temporalio/dashboards/helm/misc/matching-service-specific.json
        datasource: TemporalMetrics
      misc-worker-service-specific-github:
        url: https://raw.githubusercontent.com/temporalio/dashboards/helm/misc/worker-service-specific.json
        datasource: TemporalMetrics

cassandra:
  enabled: false
  persistence:
    enabled: false
  image:
    repo: cassandra
    tag: 3.11.3
    pullPolicy: IfNotPresent
  config:
    cluster_size: 3
    ports:
      cql: 9042
    num_tokens: 4
    max_heap_size: 512M
    heap_new_size: 128M
    seed_size: 0
  service:
    type: ClusterIP

mysql:
  enabled: false
